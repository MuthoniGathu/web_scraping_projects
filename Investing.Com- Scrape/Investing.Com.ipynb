{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from time import time,sleep\n",
    "from datetime import datetime, timedelta\n",
    "import schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape data from the website\n",
    "def scrape_forex_data():\n",
    "    # This section opens the browser using selenium webdriver and navigates to the this week tab\n",
    "    URL = \"https://www.investing.com/economic-calendar/\"\n",
    "\n",
    "    #open the browser\n",
    "    browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "    #load page\n",
    "    browser.get(URL)\n",
    "\n",
    "    #navigate to this week's tab\n",
    "    this_week_tab = browser.find_element(by=By.XPATH,value=\"//a[@id='timeFrame_thisWeek']\")\n",
    "\n",
    "    #click to this week's tab\n",
    "    this_week_tab.click()\n",
    "\n",
    "    sleep(2)\n",
    "\n",
    "    #print(browser.page_source.encode('utf-8'))\n",
    "\n",
    "    # create the Beautiful Soup object\n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "    # find the table with class 'js-economic-calendar-data'\n",
    "    table = soup.find('table', id='economicCalendarData')\n",
    "\n",
    "    d = {\"Date\":[], \"Time\":[], \"Currency\":[], \"Impact\":[],\"Description\":[]}\n",
    "\n",
    "    # iterate through each row in the table and extract the data for this week\n",
    "    for row in table.find_all('tr'):\n",
    "        # check if the row has a data-event-datetime attribute\n",
    "        if row.has_attr('data-event-datetime'):\n",
    "            # extract the date and time from the data-event-datetime attribute\n",
    "            event_datetime = row['data-event-datetime']\n",
    "            #parse into a Python datetime object and store as date into dictionary\n",
    "            d['Date'].append((datetime.strptime(event_datetime, '%Y/%m/%d %H:%M:%S')).date())\n",
    "            # extract time from the row and store into dictionary\n",
    "            d['Time'].append(row.find('td', class_='time').text.strip())\n",
    "            # extract currency from the row and store into dictionary\n",
    "            d['Currency'].append(row.find('td', class_='flagCur').text.strip())\n",
    "            # find all the i tags with class grayFullBullishIcon- they have impact rating\n",
    "            impact_list = row.find_all('i', class_='grayFullBullishIcon')\n",
    "            impact_level = ''\n",
    "            if len(impact_list) == 1:\n",
    "                impact_level = 'Low Impact'\n",
    "            elif len(impact_list) == 2:\n",
    "                impact_level = 'Medium Impact'\n",
    "            elif len(impact_list) == 3:\n",
    "                impact_level = 'High Impact'\n",
    "\n",
    "            d['Impact'].append(impact_level)\n",
    "            # extract impact from the row and store into dictionary\n",
    "            d['Description'].append( row.find('td', class_='event').text.strip())\n",
    "        \n",
    "    investing_df = pd.DataFrame.from_dict(d) \n",
    "\n",
    "    # Save the data to a CSV file\n",
    "    reload_date = datetime.today().strftime('%Y-%m-%d')\n",
    "    week_num = datetime.today().strftime('%U')\n",
    "    year_num = datetime.today().strftime('%Y')\n",
    "    filename = f'investing_df{reload_date}_week{week_num}_year{year_num}.csv'\n",
    "     #insert path of folder you want the csv to be in between r''\n",
    "    investing_df.to_csv(r'' + '\\\\' + filename, header=True, index=False)\n",
    "    \n",
    "        \n",
    "    # Close the web driver\n",
    "    browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_forex_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
